{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#basics\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import trange, tqdm\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#models\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from oml.registry.models import get_extractor_by_cfg\n",
    "from oml.registry.transforms import TRANSFORMS_REGISTRY, get_transforms_by_cfg\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from oml.const import MEAN, PAD_COLOR, STD, TNormParam\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "\n",
    "#preprocessing\n",
    "import torchvision.transforms as T\n",
    "\n",
    "#dataset\n",
    "from wildlife_tools.data import FeatureDataset\n",
    "from wildlife_datasets.datasets import AnimalCLEF2025\n",
    "\n",
    "#features\n",
    "\n",
    "from wildlife_tools.features import DeepFeatures\n",
    "from wildlife_tools.features.local import AlikedExtractor, DiskExtractor, SuperPointExtractor\n",
    "from wildlife_tools.similarity.wildfusion import SimilarityPipeline, WildFusion\n",
    "\n",
    "from wildlife_tools.similarity.pairwise.collectors import CollectCounts\n",
    "from wildlife_tools.similarity import CosineSimilarity\n",
    "\n",
    "#for wildfusion\n",
    "from wildlife_tools.similarity.wildfusion import SimilarityPipeline, WildFusion\n",
    "from wildlife_tools.similarity.pairwise.lightglue import MatchLightGlue\n",
    "#calibration\n",
    "from wildlife_tools.similarity.calibration import IsotonicCalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_path = '.'\n",
    "\n",
    "train = pd.read_csv(f'{root_path}/train.csv')\n",
    "train = train[['file_name', 'individual_name', 'sequence']]\n",
    "train['image_id'] = train.index\n",
    "train['identity'] = train['individual_name']\n",
    "train['path'] = 'train/' + train['file_name']\n",
    "train = train[['image_id', 'path', 'identity', 'sequence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: solution1/ (stored 0%)\n",
      "  adding: solution1/ requirements.txt (deflated 52%)\n",
      "  adding: solution1/README.md (stored 0%)\n",
      "  adding: solution1/submission.csv (deflated 50%)\n",
      "  adding: solution1/arkface_effnet_b7_sc089_768.ckpt?download=true (deflated 8%)\n",
      "  adding: solution1/train_effnet.ipynb (deflated 73%)\n",
      "  adding: solution1/.ipynb_checkpoints/ (stored 0%)\n",
      "  adding: solution1/.ipynb_checkpoints/inference-checkpoint.ipynb (deflated 80%)\n",
      "  adding: solution1/.ipynb_checkpoints/README-checkpoint.md (stored 0%)\n",
      "  adding: solution1/.ipynb_checkpoints/train_effnet-checkpoint.ipynb (deflated 73%)\n",
      "  adding: solution1/.ipynb_checkpoints/ requirements-checkpoint.txt (deflated 52%)\n",
      "  adding: solution1/inference.ipynb (deflated 80%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r solution1.zip solution1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: solution2/ (stored 0%)\n",
      "  adding: solution2/requirements.txt (deflated 52%)\n",
      "  adding: solution2/README.md (stored 0%)\n",
      "  adding: solution2/submission.csv (deflated 50%)\n",
      "  adding: solution2/best-v33.ckpt?download=true"
     ]
    }
   ],
   "source": [
    "!zip -r solution2.zip solution2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = train.identity.unique()\n",
    "labels_train, labels_val = train_test_split(labels, test_size=0.33, random_state=42, shuffle=True)\n",
    "\n",
    "train[\"split\"] = np.where(train[\"identity\"].isin(labels_train), \"train\", \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.DataFrame()\n",
    "test['path'] = glob(f'{root_path}/test/*')\n",
    "test['image_id'] = test.index\n",
    "test['identity'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = AnimalCLEF2025(root=root_path, metadata=train, load_label=True)\n",
    "test_dataset = AnimalCLEF2025(root=root_path, metadata=test, load_label=True)\n",
    "dataset_calibration = AnimalCLEF2025(root=root_path, df=train_dataset.metadata.sample(200), load_label=True)\n",
    "\n",
    "dataset_query = test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_sub(sims):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    mapper_names = dict(zip(dataset_query.metadata.index, dataset_query.metadata.path))\n",
    "    result_df = pd.DataFrame()\n",
    "    preds = [np.argsort(sim)[::-1] for sim in sims]\n",
    "    new_preds = []\n",
    "    for p in preds:\n",
    "        new_p = [mapper_names[p_i].split('/')[-1] for p_i in p]\n",
    "        new_preds.append(new_p)\n",
    "    result_df['image_name'] = [mapper_names[i].split('/')[-1] for i in range(len(preds))]\n",
    "    result_df['recommendation'] = new_preds\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_by_sequence(dataset, sims, label_mapper, series_mapper):\n",
    "    sims_sorted = [np.argsort(sim)[::-1] for sim in sims]\n",
    "    label_array = np.array([label_mapper[i] for i in range(len(label_mapper))])\n",
    "    series_array = np.array([series_mapper[i] for i in range(len(series_mapper))])\n",
    "    preds_cleand = []\n",
    "    for t_i, p in enumerate(sims_sorted):\n",
    "        t_seq = series_array[t_i]\n",
    "        sorted_indices = sims_sorted[t_i]\n",
    "        mask = series_array[sorted_indices] != t_seq\n",
    "        filtered_indices = sorted_indices[mask]\n",
    "        preds = label_array[filtered_indices]\n",
    "        preds_cleand.append(preds)\n",
    "    return preds_cleand\n",
    "\n",
    "def cmc(preds, true_labels):\n",
    "\n",
    "    values = []\n",
    "    for p, tr in zip(preds, true_labels):\n",
    "        cur_value = 0.0\n",
    "        was_classes = []\n",
    "        for p_i in p:\n",
    "            if p_i not in was_classes:\n",
    "                was_classes.append(p_i)\n",
    "            if len(was_classes) == 5:\n",
    "                break\n",
    "        if tr in was_classes:\n",
    "            cur_value = [1,0.9,0.8,0.7,0.6][was_classes.index(tr)]\n",
    "        values.append(cur_value)\n",
    "\n",
    "    return np.mean(values)\n",
    "\n",
    "def score(sims):\n",
    "    label_maper = dict(zip(dataset_query.metadata.index,dataset_query.metadata['identity']))\n",
    "    series_maper = dict(zip(dataset_query.metadata.index,dataset_query.metadata['sequence']))\n",
    "\n",
    "    cleaned = clean_by_sequence(dataset_query, sims, label_maper, series_maper)\n",
    "    scored = cmc(cleaned, dataset_query.metadata.identity)\n",
    "    print('CMC@5', scored)\n",
    "    return scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    a, b = torch.tensor(a), torch.tensor(b)\n",
    "    similarity = torch.matmul(F.normalize(a), F.normalize(b).T)\n",
    "    return similarity.numpy()\n",
    "\n",
    "class CosineSimilarity:\n",
    "\n",
    "    def __call__(self, query: FeatureDataset, database: FeatureDataset, **kwargs) -> np.ndarray:\n",
    "        return cosine_similarity(query.features, database.features)\n",
    "\n",
    "def manhattan_distance(a, b):\n",
    "    a = torch.tensor(a)\n",
    "    b = torch.tensor(b)\n",
    "    dists = torch.cdist(a, b, p=1)  # p=1 for Manhattan\n",
    "    return dists.numpy()\n",
    "\n",
    "class ManhattanDistance:\n",
    "    def __call__(self, query: FeatureDataset, database: FeatureDataset, **kwargs) -> np.ndarray:\n",
    "        return - manhattan_distance(query.features, database.features)\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    a = torch.tensor(a)\n",
    "    b = torch.tensor(b)\n",
    "    dists = torch.cdist(a, b, p=2)  # p=2 for Euclidean\n",
    "    return dists.numpy()\n",
    "\n",
    "class EuclideanDistance:\n",
    "    def __call__(self, query: FeatureDataset, database: FeatureDataset, **kwargs) -> np.ndarray:\n",
    "        return - euclidean_distance(query.features, database.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Weights for PreRanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_hits(dataset0, dataset1):\n",
    "    gt0 = dataset0.labels_string\n",
    "    gt1 = dataset1.labels_string\n",
    "    gt_grid0 = np.tile(gt0, (len(gt1), 1)).T\n",
    "    gt_grid1 = np.tile(gt1, (len(gt0), 1))\n",
    "    return gt_grid0 == gt_grid1\n",
    "\n",
    "class MultiRankerPipeline:\n",
    "    def __init__(self, matchers, extractor, calibration, transform):\n",
    "        self.matchers = matchers\n",
    "        self.calibration = calibration\n",
    "        self.calibration_done = False\n",
    "        self.extractor = extractor\n",
    "        self.transform = transform\n",
    "\n",
    "    def get_feature_dataset(self, dataset):\n",
    "\n",
    "        if self.transform is not None:\n",
    "            dataset.transform = self.transform\n",
    "        if self.extractor is not None:\n",
    "            return self.extractor(dataset)\n",
    "        else:\n",
    "            return dataset\n",
    "\n",
    "    def fit_calibration(self, dataset0, dataset1):\n",
    "\n",
    "        if self.calibration is None:\n",
    "            raise ValueError(\"Calibration method is not assigned.\")\n",
    "\n",
    "        dataset0 = self.get_feature_dataset(dataset0)\n",
    "        dataset1 = self.get_feature_dataset(dataset1)\n",
    "        self.calibration_models = []\n",
    "        for matcher in self.matchers:\n",
    "            score = matcher(dataset0, dataset1)\n",
    "            hits = get_hits(dataset0, dataset1)\n",
    "            calibration = self.calibration()\n",
    "            calibration.fit(score.flatten(), hits.flatten())\n",
    "            self.calibration_models.append(calibration)\n",
    "        self.calibration_done = True\n",
    "\n",
    "    def __call__(self, dataset0, dataset1) -> np.ndarray:\n",
    "\n",
    "        if not self.calibration_done:\n",
    "            raise ValueError(\"Calibration is not fitted. Use fit_calibration method.\")\n",
    "\n",
    "        dataset0 = self.get_feature_dataset(dataset0)\n",
    "        dataset1 = self.get_feature_dataset(dataset1)\n",
    "        scores = []\n",
    "        for matcher,calibration in zip(self.matchers, self.calibration_models):\n",
    "            score = matcher(dataset0, dataset1)\n",
    "            if calibration is not None:\n",
    "                    score = calibration.predict(score.flatten()).reshape(score.shape)\n",
    "            scores.append(score)\n",
    "        return np.stack(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mega_pipe(transforms, model_name, device, dataset_query, dataset_database, use_custom=True ):\n",
    "    \n",
    "    if not use_custom:\n",
    "        model_mega = timm.create_model(model_name, num_classes=0, pretrained=True)\n",
    "    else:\n",
    "        cfg = {\n",
    "            \"extractor\":{\n",
    "                \"name\": \"vit\",\n",
    "                \"args\":{\n",
    "                    \"arch\": \"vitl14_reg\",\n",
    "                    \"normalise_features\": True,            \n",
    "                    \"weights\": \"best-v33.ckpt?download=true\"\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "        model = get_extractor_by_cfg(cfg['extractor'])\n",
    "        model_mega = model\n",
    "    \n",
    "    matcher_mega = MultiRankerPipeline(\n",
    "        matchers = [CosineSimilarity(), ManhattanDistance(), EuclideanDistance()],\n",
    "        extractor = DeepFeatures(model=model_mega, device=device, batch_size=16),\n",
    "        transform = transforms,\n",
    "        calibration = IsotonicCalibration\n",
    "    )\n",
    "    \n",
    "    matcher_mega.fit_calibration(dataset_calibration, dataset_calibration)\n",
    "    sims = matcher_mega(\n",
    "        dataset_query,\n",
    "        dataset_database\n",
    "    )\n",
    "\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_matched_sims(sims, k):\n",
    "    sims_corrected = np.where((0.99 <= sims) & (sims <= 1.0), -np.inf, sims)\n",
    "    best_matches = sims_corrected.argsort(-1)[:, ::-1][:, :k]\n",
    "    sims = sims[best_matches].mean(axis=1)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResizeAndPad:\n",
    "    def __init__(self, size, pad_value=0):\n",
    "        self.size = size\n",
    "        self.pad_value = pad_value\n",
    "\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        scale = self.size / max(w, h)\n",
    "        new_w, new_h = int(w * scale), int(h * scale)\n",
    "        img = img.resize((new_w, new_h), Image.BILINEAR)\n",
    "\n",
    "        pad_w = self.size - new_w\n",
    "        pad_h = self.size - new_h\n",
    "\n",
    "        pad_left = pad_w // 2\n",
    "        pad_right = pad_w - pad_left\n",
    "        pad_top = pad_h // 2\n",
    "        pad_bottom = pad_h - pad_top\n",
    "\n",
    "        padding = (pad_left, pad_top, pad_right, pad_bottom)\n",
    "        img = T.functional.pad(img, padding, fill=self.pad_value, padding_mode='constant')\n",
    "        return img\n",
    "\n",
    "transform_1 = T.Compose([\n",
    "    ResizeAndPad(img_sz_mega, pad_value=PAD_COLOR),\n",
    "    T.RandomHorizontalFlip(p=1.0),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=MEAN, std=STD),\n",
    "])\n",
    "\n",
    "transform_2 = T.Compose([\n",
    "    ResizeAndPad(img_sz_mega, pad_value=PAD_COLOR),\n",
    "    T.RandomVerticalFlip(p=1.0),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=MEAN, std=STD),\n",
    "])\n",
    "\n",
    "transform_3 = T.Compose([\n",
    "    ResizeAndPad(img_sz_mega, pad_value=PAD_COLOR),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=MEAN, std=STD),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_sz_mega = 224\n",
    "mega_transforms = [\n",
    "    transform_3,\n",
    "    transform_2,\n",
    "    transform_1\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run with transforms:  Compose(\n",
      "    <__main__.ResizeAndPad object at 0x7f1a67046010>\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      ")\n",
      "Prefix <model.model.> was removed from the state dict.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 13/13 [00:04<00:00,  2.63it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 299/299 [01:16<00:00,  3.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 299/299 [01:18<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run with transforms:  Compose(\n",
      "    <__main__.ResizeAndPad object at 0x7f1a670460d0>\n",
      "    RandomVerticalFlip(p=1.0)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      ")\n",
      "Prefix <model.model.> was removed from the state dict.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.70it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 299/299 [01:17<00:00,  3.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 299/299 [01:21<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run with transforms:  Compose(\n",
      "    <__main__.ResizeAndPad object at 0x7f1a671a88d0>\n",
      "    RandomHorizontalFlip(p=1.0)\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
      ")\n",
      "Prefix <model.model.> was removed from the state dict.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.80it/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 13/13 [00:03<00:00,  3.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 299/299 [01:18<00:00,  3.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████| 299/299 [01:19<00:00,  3.78it/s]\n"
     ]
    }
   ],
   "source": [
    "results_mega = []\n",
    "devices = ['cuda:0', 'cuda:0', 'cuda:0']\n",
    "for device, tr in zip(devices, mega_transforms):\n",
    "    print('run with transforms: ', tr)\n",
    "    results_mega.append(\n",
    "        mega_pipe(\n",
    "            tr, \n",
    "            'hf-hub:BVRA/MegaDescriptor-L-384',\n",
    "            device, \n",
    "            dataset_query=dataset_query,\n",
    "            dataset_database=dataset_query,\n",
    "            use_custom=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sims_mega_blended = np.array([i[0] + 1/5 * i[1] + 1/5 * i[2] for i in results_mega]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sims_mega_blended_extra = find_matched_sims(sims_mega_blended, k=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sims_mega_blended = 2/3 * sims_mega_blended + 1/3 * sims_mega_blended_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pairs(priority,B=100):\n",
    "    _, idx1 = torch.topk(torch.tensor(priority), min(B, priority.shape[1]))\n",
    "    idx0 = np.indices(idx1.numpy().shape)[0]\n",
    "    grid_indices = np.stack([idx0.flatten(), idx1.flatten()]).T\n",
    "    return grid_indices\n",
    "\n",
    "pairs = get_pairs(sims_mega_blended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiTreshSimilarityPipeline:\n",
    "    def __init__(self, matcher = None, extractor = None, calibration = None, transform = None):\n",
    "        self.matcher = matcher\n",
    "        self.calibration_type = calibration\n",
    "        self.calibration_done = False\n",
    "        self.extractor = extractor\n",
    "        self.transform = transform\n",
    "\n",
    "    def get_feature_dataset(self, dataset):\n",
    "        if self.transform is not None:\n",
    "            dataset.transform = self.transform\n",
    "        if self.extractor is not None:\n",
    "            return self.extractor(dataset)\n",
    "        else:\n",
    "            return dataset\n",
    "\n",
    "    def fit_calibration(self, dataset0, dataset1):\n",
    "        dataset0 = self.get_feature_dataset(dataset0)\n",
    "        dataset1 = self.get_feature_dataset(dataset1)\n",
    "        score = self.matcher(dataset0, dataset1)\n",
    "        self.calibrators = {}\n",
    "        hits = get_hits(dataset0, dataset1)\n",
    "        \n",
    "        for k in score:\n",
    "            calibration = self.calibration_type()\n",
    "            calibration.fit(score[k].flatten(), hits.flatten())\n",
    "            self.calibrators[k] = calibration\n",
    "            \n",
    "        self.calibration_done = True\n",
    "\n",
    "    def __call__(self, dataset0, dataset1, pairs = None):\n",
    "        if not self.calibration_done:\n",
    "            raise ValueError(\"Calibration is not fitted. Use fit_calibration method.\")\n",
    "\n",
    "        dataset0 = self.get_feature_dataset(dataset0)\n",
    "        dataset1 = self.get_feature_dataset(dataset1)\n",
    "        score = self.matcher(dataset0, dataset1, pairs=pairs)\n",
    "        for k in score:\n",
    "            calibration = self.calibrators[k]\n",
    "            if pairs is not None:\n",
    "                pairs = np.array(pairs)\n",
    "                idx0 = pairs[:, 0]\n",
    "                idx1 = pairs[:, 1]\n",
    "                score[k][idx0, idx1] = calibration.predict(score[k][idx0, idx1])\n",
    "            else:\n",
    "                 score[k] = calibration.predict(score[k].flatten()).reshape(score[k].shape)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def superpoint_pipe(transforms, num_keypoints, thrs):\n",
    "\n",
    "    matcher = MultiTreshSimilarityPipeline(\n",
    "        matcher = MatchLightGlue(\n",
    "            features='superpoint',\n",
    "            device='cuda',\n",
    "            batch_size=16,\n",
    "            collector = CollectCounts(thresholds=thrs)\n",
    "        ),\n",
    "        extractor = SuperPointExtractor(max_num_keypoints=num_keypoints),\n",
    "        transform = transforms,\n",
    "        calibration = IsotonicCalibration\n",
    "    )\n",
    "\n",
    "    matcher.fit_calibration(dataset_calibration, dataset_calibration)\n",
    "    \n",
    "    sims = matcher(\n",
    "        dataset_query,\n",
    "        dataset_query,\n",
    "        pairs=pairs\n",
    "    )\n",
    "\n",
    "    sims_cor = {}\n",
    "    for k in sims:\n",
    "       sims_cor[k] = np.where(np.isnan(sims[k]), -np.inf, sims[k])\n",
    "\n",
    "    return sims_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aliked_transforms_512 = [\n",
    "    T.Compose([\n",
    "        T.Resize([512, 512]),\n",
    "        T.ToTensor(),\n",
    "    ]),\n",
    "    T.Compose([\n",
    "        T.Resize([512, 512]),\n",
    "        T.RandomVerticalFlip(p=1),\n",
    "        T.ToTensor(),\n",
    "    ]),\n",
    "    T.Compose([\n",
    "        T.Resize([512, 512]),\n",
    "        T.RandomHorizontalFlip(p=1),\n",
    "        T.ToTensor(),\n",
    "    ])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_superpoint_512 = []\n",
    "for tr in aliked_transforms_512:\n",
    "    print('run with transforms: ', tr)\n",
    "    results_superpoint_512.append(\n",
    "        superpoint_pipe(tr, num_keypoints=384, thrs=[0.4, 0.5, 0.6, 0.7])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sims = np.array([i[0.6] for i in results_superpoint_512]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = make_sub(final_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: subs/submission_2.csv (deflated 50%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1c202c9f6e4877a6334c1e46964e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "submission_2.zip:   0%|          | 0.00/457M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/seyolax/subs_ntoii_final/commit/149e4fff319c318894a3b89143e5e4fb0a021b8e', commit_message='Upload submission_2.zip with huggingface_hub', commit_description='', oid='149e4fff319c318894a3b89143e5e4fb0a021b8e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !zip submission.zip submission.csv\n",
    "# from huggingface_hub import HfApi\n",
    "# api = HfApi(token=\"\")\n",
    "# api.upload_file(\n",
    "#     path_or_fileobj=\"submission.zip\",\n",
    "#     path_in_repo=\"submission.zip\",\n",
    "#     repo_id=\"seyolax/subs_ntoii_final\",\n",
    "#     repo_type=\"dataset\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11223220,
     "sourceId": 91451,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 11483707,
     "sourceId": 91496,
     "sourceType": "competition"
    },
    {
     "datasetId": 7078362,
     "sourceId": 11316339,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 292925,
     "modelInstanceId": 271937,
     "sourceId": 322715,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
