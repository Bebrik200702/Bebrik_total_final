{"cells":[{"id":"686bfa98-628e-4ed0-a896-fc5cb04be654","cell_type":"code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:01:51.292733Z","iopub.execute_input":"2025-04-21T21:01:51.293303Z","iopub.status.idle":"2025-04-21T21:02:03.845856Z","shell.execute_reply.started":"2025-04-21T21:01:51.293279Z","shell.execute_reply":"2025-04-21T21:02:03.845265Z"}},"source":"import os\nimport gc\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GroupKFold\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.auto import tqdm, trange\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom transformers import get_cosine_schedule_with_warmup,get_linear_schedule_with_warmup, AutoModel, AutoTokenizer, AutoModelForMultipleChoice, AutoConfig\nimport wandb\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"","execution_count":1,"outputs":[]},{"id":"15b28602-9f1f-4986-a510-ddb7edc9a4c6","cell_type":"code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:02:03.847097Z","iopub.execute_input":"2025-04-21T21:02:03.847380Z","iopub.status.idle":"2025-04-21T21:02:03.939439Z","shell.execute_reply.started":"2025-04-21T21:02:03.847354Z","shell.execute_reply":"2025-04-21T21:02:03.938885Z"}},"source":"maper = {'business': 0, 'sport': 1, 'tech': 2,'entertainment': 3}\ninv_maper = {v:k for k,v in maper.items()}","execution_count":2,"outputs":[]},{"id":"2458ff63-0850-4ba1-97a4-91a9a0a64958","cell_type":"code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:02:03.940124Z","iopub.execute_input":"2025-04-21T21:02:03.940381Z","iopub.status.idle":"2025-04-21T21:02:03.945678Z","shell.execute_reply.started":"2025-04-21T21:02:03.940356Z","shell.execute_reply":"2025-04-21T21:02:03.945128Z"}},"source":"class TextDataset(Dataset):\n    def __init__(self, df, tokenizer):\n        super().__init__()\n        self.data = df\n        self.tokenizer = tokenizer\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        row = self.data.iloc[index]        \n        \n        encodes = self.tokenizer.encode_plus(\n            row['text'],\n            max_length=384,\n            truncation=True,\n            padding='max_length',\n            return_tensors='pt'\n        )\n        \n        return {\n            'input_ids': encodes.input_ids.squeeze(0),\n            'attention_mask': encodes.attention_mask.squeeze(0),\n            'token_type_ids': encodes.token_type_ids.squeeze(0),\n            'labels': torch.tensor(row['label'])\n        }","execution_count":3,"outputs":[]},{"id":"b8f650ad-bf8a-42f0-898f-70cbc407cfd9","cell_type":"code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:02:23.675301Z","iopub.execute_input":"2025-04-21T21:02:23.675795Z","iopub.status.idle":"2025-04-21T21:02:23.682017Z","shell.execute_reply.started":"2025-04-21T21:02:23.675770Z","shell.execute_reply":"2025-04-21T21:02:23.681370Z"}},"source":"class MeanPooling(nn.Module):\n    def __init__(self, clamp_min=1e-9):\n        super(MeanPooling, self).__init__()\n        self.clamp_min = clamp_min\n\n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=self.clamp_min)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n\n\nclass TextModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = AutoModel.from_pretrained('/bohr/debertasmall3-nhez/v1/deberta_small/')\n        self.pooler = MeanPooling()\n        self.head_drop = nn.Dropout(0.00)\n        self.head = nn.Linear(768,4)\n        \n    def forward(self, batch):\n        out = self.model(batch['input_ids'],attention_mask=batch['attention_mask'])\n        logits = self.pooler(out[0], batch['attention_mask'])\n        logits = self.head_drop(logits)\n        logits = self.head(logits)\n        return logits","execution_count":4,"outputs":[]},{"id":"95c86158-5204-4ba8-853e-88d30ea7acfc","cell_type":"code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:02:25.540659Z","iopub.execute_input":"2025-04-21T21:02:25.541339Z","iopub.status.idle":"2025-04-21T21:02:29.402104Z","shell.execute_reply.started":"2025-04-21T21:02:25.541315Z","shell.execute_reply":"2025-04-21T21:02:29.401532Z"}},"source":"tokenizer = AutoTokenizer.from_pretrained('/bohr/debertasmall3-nhez/v1/deberta_small/')","execution_count":5,"outputs":[]},{"id":"c8de8982-b6a7-4b6b-840b-8d2b52ca5369","cell_type":"code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:02:29.403190Z","iopub.execute_input":"2025-04-21T21:02:29.403440Z","iopub.status.idle":"2025-04-21T21:02:50.473916Z","shell.execute_reply.started":"2025-04-21T21:02:29.403417Z","shell.execute_reply":"2025-04-21T21:02:50.473066Z"}},"source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = TextModel().to(device)","execution_count":6,"outputs":[]},{"id":"7eb27c9b-46ef-408d-8ac3-e7f32ad546eb","cell_type":"code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:03:03.218688Z","iopub.execute_input":"2025-04-21T21:03:03.219577Z","iopub.status.idle":"2025-04-21T21:03:03.223990Z","shell.execute_reply.started":"2025-04-21T21:03:03.219552Z","shell.execute_reply":"2025-04-21T21:03:03.223449Z"}},"source":"model.load_state_dict(torch.load('/bohr/weightsV2de-xb26/v1/weightsV3.pt'))","execution_count":7,"outputs":[]},{"id":"55f33f7e-8bed-4638-9142-3b6f623ea566","cell_type":"code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:04:24.151382Z","iopub.execute_input":"2025-04-21T21:04:24.152184Z","iopub.status.idle":"2025-04-21T21:04:25.198431Z","shell.execute_reply.started":"2025-04-21T21:04:24.152150Z","shell.execute_reply":"2025-04-21T21:04:25.197625Z"}},"source":"device = 'cpu'\nmodel = model.to(device)","execution_count":12,"outputs":[]},{"id":"61e3d1b8-b3ea-4287-aade-7b0a98906ac1","cell_type":"code","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-21T21:04:26.294050Z","iopub.execute_input":"2025-04-21T21:04:26.294644Z","iopub.status.idle":"2025-04-21T21:06:36.745529Z","shell.execute_reply.started":"2025-04-21T21:04:26.294619Z","shell.execute_reply":"2025-04-21T21:06:36.744456Z"}},"source":"#以下为测试过程，The test process. \nif os.environ.get('DATA_PATH'):\n    data_path = os.environ.get(\"DATA_PATH\") + \"/\"  \nelse:\n    print(\"Baseline运行时，因为无法读取测试集，所以会有此条报错，属于正常现象\")  #Baseline运行时，因为无法读取测试集，所以会有此条报错，属于正常现象\n    print(\"When the baseline is running, this error message will appear because the test set cannot be read, which is a normal phenomenon.\") #When the baseline is running, this error message will appear because the test set cannot be read, which is a normal phenomenon.\ntest_df = pd.read_csv(data_path+\"test_news_nolabel.csv\")\n\ntest_df['label'] = 0\ntest_dataset = TextDataset(test_df,tokenizer)\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=16,\n    shuffle=False,\n    num_workers=4,\n    pin_memory=True\n)\nmodel.eval()\npredicted_labels = []\nwith torch.no_grad():\n    for batch in tqdm(test_dataloader):\n        for k in batch:\n            batch[k] = batch[k].to(device)\n            \n        with torch.autocast(str(device)):\n            logits = model(batch)\n            \n        _, predicted = torch.max(logits, 1)\n        predicted_labels.extend(predicted.cpu().numpy())\n\ntest_df[\"category\"] = predicted_labels\ntest_df['category'] = test_df['category'].map(inv_maper)\n\noutput_path = \"submission.csv\"\ntest_df[['text','category']].to_csv(output_path, index=False)\nprint(\"submission.csv is generated successfully\")","execution_count":13,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11505285,"sourceType":"datasetVersion","datasetId":7213662}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat":4,"nbformat_minor":4}