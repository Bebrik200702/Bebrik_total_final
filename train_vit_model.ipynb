{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c51a6acf-b519-4d9f-96aa-76c38503ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df.head()\n",
    "\n",
    "labels = train_df.label.unique()\n",
    "labels_train, labels_val = train_test_split(labels, test_size=0.125, random_state=42, shuffle=True)\n",
    "\n",
    "# Добавляем путь к файлам и определяем split\n",
    "train_df[\"path\"] = \"train/\" + train_df[\"file_name\"]\n",
    "train_df[\"split\"] = np.where(train_df[\"label\"].isin(labels_train), \"train\", \"validation\")\n",
    "\n",
    "# Инициализируем и заполняем столбцы is_query и is_gallery\n",
    "train_df[[\"is_query\", \"is_gallery\"]] = np.nan\n",
    "mask_validation = train_df[\"split\"] == \"validation\"\n",
    "train_df.loc[mask_validation, [\"is_query\", \"is_gallery\"]] = 1\n",
    "train_df.head()\n",
    "\n",
    "train_df.to_csv(\"train_tiger_small.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8294e9f1-1d09-4184-874d-cb8d66f52ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Tuple\n",
    "\n",
    "import hydra\n",
    "import pytorch_lightning as pl\n",
    "from omegaconf import DictConfig\n",
    "from oml.const import TCfg\n",
    "from oml.datasets.images import get_retrieval_images_datasets\n",
    "from oml.lightning.callbacks.metric import MetricValCallback\n",
    "from oml.lightning.modules.extractor import ExtractorModule, ExtractorModuleDDP\n",
    "from oml.lightning.pipelines.parser import (\n",
    "    check_is_config_for_ddp,\n",
    "    parse_logger_from_config,\n",
    "    parse_ckpt_callback_from_config,\n",
    "    parse_engine_params_from_config,\n",
    "    parse_sampler_from_config,\n",
    "    parse_scheduler_from_config,\n",
    ")\n",
    "from oml.metrics.embeddings import EmbeddingMetrics\n",
    "from oml.registry.losses import get_criterion_by_cfg\n",
    "from oml.registry.models import get_extractor_by_cfg\n",
    "from oml.registry.optimizers import get_optimizer_by_cfg\n",
    "from oml.registry.transforms import TRANSFORMS_REGISTRY, get_transforms_by_cfg\n",
    "from oml.utils.misc import dictconfig_to_dict, set_global_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from oml.registry import get_transforms_for_pretrained\n",
    "\n",
    "import torch\n",
    "\n",
    "import albumentations as albu\n",
    "import cv2\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from oml.const import MEAN, PAD_COLOR, STD, TNormParam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb6429e-564b-44e0-9262-07eab9738e50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "postfix = \"metric_learning\"\n",
    "\n",
    "current_dateTime = datetime.now()\n",
    "y = current_dateTime.year\n",
    "month = current_dateTime.month\n",
    "d = current_dateTime.day\n",
    "hour = current_dateTime.hour\n",
    "minute = current_dateTime.minute\n",
    "s = current_dateTime.second\n",
    "ms = current_dateTime.microsecond\n",
    "\n",
    "cfg: TCfg = {\n",
    "    \"postfix\": postfix,\n",
    "    \"seed\": 42,\n",
    "    \"image_size\": 224,\n",
    "    \"accelerator\": \"gpu\",\n",
    "    \"devices\": 1, \n",
    "    \"dataframe_name\": \"train_tiger_small.csv\",\n",
    "    \"dataset_root\": \"./\",\n",
    "    \"logs_root\": \"logs/\",\n",
    "    \"logs_folder\": f\"{y}-{month}-{d}-{hour}-{minute}-{s}-{ms}_{postfix}\",\n",
    "    \"num_workers\": 4,\n",
    "    \"cache_size\": 0,\n",
    "    \"sampler\": None,\n",
    "    \"bs_train\": 16,\n",
    "    \"bs_val\": 32,  \n",
    "    \"max_epochs\": 10,\n",
    "    \"valid_period\": 2,\n",
    "    \"save_dir\": \".\",\n",
    "\n",
    "    \"metric_args\": {\n",
    "        \"map_top_k\": [1, 3, 5], \n",
    "    },\n",
    "\n",
    "    \"log_images\": False,\n",
    "    \"metric_for_checkpointing\": \"OVERALL/map/5\",\n",
    "\n",
    "\n",
    "    \"extractor\":{\n",
    "        \"name\": \"vit\",\n",
    "        \"args\":{\n",
    "            \"arch\": \"vitl14_reg\",\n",
    "            \"normalise_features\": True,\n",
    "            \"weights\": \"vitl14_reg_dinov2\",            \n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"criterion\": {\n",
    "        \"name\": \"arcface\",\n",
    "        \"args\":{\n",
    "            \"m\": 0.50,\n",
    "            \"in_features\": 1024,\n",
    "            \"num_classes\": 93,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"optimizer\":{\n",
    "        \"name\": \"adam\",\n",
    "        \"args\":{\n",
    "            \"lr\": 1e-5,\n",
    "        },\n",
    "    },\n",
    "\n",
    "    \"scheduling\": None,\n",
    "    \"logger\":{\n",
    "        \"name\": \"tensorboard\",  \n",
    "        \"args\":{\n",
    "            \"save_dir\": \".\"\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a53ca7-d7c7-4381-837a-24ecff625fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_transforms(im_size: int, mean: TNormParam = MEAN, std: TNormParam = STD) -> albu.Compose:\n",
    "    \"\"\"\n",
    "    Use default oml albu augs, but without HorizontalFlip.\n",
    "    :param im_size:\n",
    "    :param mean:\n",
    "    :param std:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return albu.Compose(\n",
    "        [\n",
    "            albu.LongestMaxSize(max_size=im_size),\n",
    "            albu.PadIfNeeded(\n",
    "                min_height=im_size,\n",
    "                min_width=im_size,\n",
    "                border_mode=cv2.BORDER_CONSTANT,\n",
    "                value=PAD_COLOR,\n",
    "            ),\n",
    "            albu.Normalize(mean=mean, std=std),\n",
    "            ToTensorV2(),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "791ed94b-4017-4465-b1bf-4b6d86611a4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_transforms = get_transforms(cfg['image_size'])\n",
    "def get_retrieval_loaders(cfg: TCfg) -> Tuple[DataLoader, DataLoader]:\n",
    "    train_dataset, valid_dataset = get_retrieval_images_datasets(\n",
    "        dataset_root=Path(cfg['dataset_root']),\n",
    "        transforms_train=model_transforms,\n",
    "        transforms_val=model_transforms,\n",
    "        dataframe_name=cfg['dataframe_name'],\n",
    "        cache_size=cfg['cache_size'],\n",
    "        verbose=cfg.get('show_dataset_warnings', True),\n",
    "    )    \n",
    "\n",
    "    loader_train = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        num_workers=cfg['num_workers'],\n",
    "        batch_size=cfg['bs_train'],\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    loader_val = DataLoader(dataset=valid_dataset, batch_size=cfg['bs_val'], num_workers=cfg['num_workers'])\n",
    "\n",
    "    return loader_train, loader_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914932e-5710-42ae-bc89-e8c3767fb849",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extractor_training_pipeline(cfg: TCfg) -> None:\n",
    "    set_global_seed(cfg['seed'])\n",
    "\n",
    "    cfg = dictconfig_to_dict(cfg)\n",
    "    print(cfg)\n",
    "    \n",
    "    logger = parse_logger_from_config(cfg)\n",
    "    logger.log_pipeline_info(cfg)\n",
    "\n",
    "    loader_train, loaders_val = get_retrieval_loaders(cfg)\n",
    "    extractor = get_extractor_by_cfg(cfg['extractor'])\n",
    "    criterion = get_criterion_by_cfg(cfg['criterion'], **{'label2category': loader_train.dataset.get_label2category()})\n",
    "    optimizable_parameters = [\n",
    "        {'lr': cfg['optimizer']['args']['lr'], 'params': extractor.parameters()},\n",
    "        {'lr': cfg['optimizer']['args']['lr'], 'params': criterion.parameters()},\n",
    "    ]\n",
    "    optimizer = get_optimizer_by_cfg(cfg['optimizer'], **{'params': optimizable_parameters})  # type: ignore\n",
    "\n",
    "    module_kwargs = {}\n",
    "    module_kwargs.update(parse_scheduler_from_config(cfg, optimizer=optimizer))\n",
    "    module_constructor = ExtractorModule  # type: ignore\n",
    "\n",
    "    pl_module = module_constructor(\n",
    "        extractor=extractor,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        input_tensors_key=loader_train.dataset.input_tensors_key,\n",
    "        labels_key=loader_train.dataset.labels_key,\n",
    "        freeze_n_epochs=cfg.get('freeze_n_epochs', 0),\n",
    "        **module_kwargs,\n",
    "    )\n",
    "\n",
    "    metrics_constructor = EmbeddingMetrics\n",
    "    metrics_calc = metrics_constructor(\n",
    "        dataset = loaders_val.dataset,\n",
    "        **cfg.get('metric_args', {}),\n",
    "    )\n",
    "\n",
    "\n",
    "    metrics_clb_constructor = MetricValCallback\n",
    "    metrics_clb = metrics_clb_constructor(\n",
    "        metric=metrics_calc,\n",
    "        log_images=False,\n",
    "    )\n",
    "\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=cfg['max_epochs'],\n",
    "        num_sanity_val_steps=0,\n",
    "        check_val_every_n_epoch=cfg['valid_period'],\n",
    "        default_root_dir=str(Path.cwd()),\n",
    "        enable_checkpointing=True,\n",
    "        enable_progress_bar=True,\n",
    "        enable_model_summary=True,\n",
    "        callbacks=[metrics_clb, parse_ckpt_callback_from_config(cfg)],\n",
    "        logger=logger,\n",
    "        precision=16,\n",
    "        **cfg.get('lightning_trainer_extra_args', {}),\n",
    "    )\n",
    "\n",
    "    trainer.fit(model=pl_module, train_dataloaders=loader_train, val_dataloaders=loaders_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6eca3-5134-4065-ae7e-948cc00cc7a1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "extractor_training_pipeline(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86a444e3-fc02-428e-8cd2-1f174d1bb759",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best-v1.ckpt',\n",
       " 'best-v10.ckpt',\n",
       " 'best-v11.ckpt',\n",
       " 'best-v12.ckpt',\n",
       " 'best-v13.ckpt',\n",
       " 'best-v14.ckpt',\n",
       " 'best-v15.ckpt',\n",
       " 'best-v16.ckpt',\n",
       " 'best-v17.ckpt',\n",
       " 'best-v18.ckpt',\n",
       " 'best-v19.ckpt',\n",
       " 'best-v2.ckpt',\n",
       " 'best-v20.ckpt',\n",
       " 'best-v21.ckpt',\n",
       " 'best-v22.ckpt',\n",
       " 'best-v23.ckpt',\n",
       " 'best-v24.ckpt',\n",
       " 'best-v25.ckpt',\n",
       " 'best-v26.ckpt',\n",
       " 'best-v27.ckpt',\n",
       " 'best-v28.ckpt',\n",
       " 'best-v29.ckpt',\n",
       " 'best-v3.ckpt',\n",
       " 'best-v30.ckpt',\n",
       " 'best-v31.ckpt',\n",
       " 'best-v32.ckpt',\n",
       " 'best-v33.ckpt',\n",
       " 'best-v4.ckpt',\n",
       " 'best-v5.ckpt',\n",
       " 'best-v6.ckpt',\n",
       " 'best-v7.ckpt',\n",
       " 'best-v8.ckpt',\n",
       " 'best-v9.ckpt',\n",
       " 'best.ckpt']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "sorted(os.listdir('./checkpoints'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
